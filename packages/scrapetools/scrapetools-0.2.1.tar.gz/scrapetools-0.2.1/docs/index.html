<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>scrapeTools API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Package <code>scrapeTools</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from .emailScraper import scrapeEmails
from .inputScraper import scrapeInputs
from .linkScraper import LinkScraper
from .phoneScraper import scrapePhoneNumbers

__all__ = [&#34;scrapeEmails&#34;, &#34;LinkScraper&#34;, &#34;scrapePhoneNumbers&#34;, &#34;scrapeInputs&#34;]</code></pre>
</details>
</section>
<section>
<h2 class="section-title" id="header-submodules">Sub-modules</h2>
<dl>
<dt><code class="name"><a title="scrapeTools.emailScraper" href="emailScraper.html">scrapeTools.emailScraper</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="scrapeTools.inputScraper" href="inputScraper.html">scrapeTools.inputScraper</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="scrapeTools.linkScraper" href="linkScraper.html">scrapeTools.linkScraper</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt><code class="name"><a title="scrapeTools.phoneScraper" href="phoneScraper.html">scrapeTools.phoneScraper</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="scrapeTools.scrapeEmails"><code class="name flex">
<span>def <span class="ident">scrapeEmails</span></span>(<span>text: str) ‑> list[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Extracts potential emails from given text
and returns as a list of strings.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scrapeEmails(text: str) -&gt; list[str]:
    &#34;&#34;&#34;Extracts potential emails from given text
    and returns as a list of strings.&#34;&#34;&#34;
    if &#34;%&#34; in text:
        # decode percent encoding
        text = unquote(text)
    for ch in [&#34;\n&#34;, &#34;\t&#34;, &#34;\r&#34;]:
        text = text.replace(ch, &#34; &#34;)
    atCount = text.count(&#34;@&#34;)
    emails = []
    if atCount &gt; 0:
        lastStopdex = 0
        for i in range(atCount):
            atdex = text.find(&#34;@&#34;, lastStopdex)
            nextAtdex = text.find(&#34;@&#34;, atdex + 1)
            try:
                chunk = (
                    text[lastStopdex:nextAtdex]
                    if nextAtdex != -1
                    else text[lastStopdex:]
                )
                chunkAtdex = chunk.find(&#34;@&#34;)
                startdex = findLastValidCharacterOffset(chunk[: chunkAtdex + 1])
                stopdex = findLastValidCharacterOffset(chunk[chunkAtdex:])
                email = chunk[chunkAtdex - startdex : stopdex + chunkAtdex + 1]
                while email[-1].isnumeric() or not email[-1].isalpha():
                    email = email[:-1]
                if validate(email):
                    emails.append(email.lower())
                &#34;&#34;&#34; The extra &#39;+ 1&#39; is to ensure lastStopdex increments
                if &#39;len(email.split(&#39;@&#39;)[1])&#39; is 0.&#34;&#34;&#34;
                lastStopdex = atdex + len(email.split(&#34;@&#34;)[1]) + 1
            except Exception as e:
                lastStopdex = atdex + 1
        emails = sorted(list(set(stripUnicode(emails))))
    return emails</code></pre>
</details>
</dd>
<dt id="scrapeTools.scrapeInputs"><code class="name flex">
<span>def <span class="ident">scrapeInputs</span></span>(<span>source: str) ‑> tuple[list[bs4.element.Tag]]</span>
</code></dt>
<dd>
<div class="desc"><p>Searches html for various user input elements.</p>
<p>Returns a tuple where each element is a list of BeautifulSoup Tag elements.</p>
<p>The tuple elements are forms, inputs, buttons, select elements,
and textAreas. If an element type was not found, it will be an empty list.</p>
<p>The inputs, buttons, select elements, and textAreas are ones
not already found in a form element.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scrapeInputs(source: str) -&gt; tuple[list[Tag]]:
    &#34;&#34;&#34;Searches html for various user input elements.

    Returns a tuple where each element is a list of BeautifulSoup Tag elements.

    The tuple elements are forms, inputs, buttons, select elements,
    and textAreas. If an element type was not found, it will be an empty list.

    The inputs, buttons, select elements, and textAreas are ones
    not already found in a form element.&#34;&#34;&#34;
    soup = BeautifulSoup(source, &#34;html.parser&#34;)
    forms = soup(&#34;form&#34;)
    for form in forms:
        form.extract()
    inputs = soup(&#34;input&#34;)
    buttons = soup(&#34;button&#34;)
    selects = soup(&#34;select&#34;)
    textAreas = soup(&#34;textAreas&#34;)

    return forms, inputs, buttons, selects, textAreas</code></pre>
</details>
</dd>
<dt id="scrapeTools.scrapePhoneNumbers"><code class="name flex">
<span>def <span class="ident">scrapePhoneNumbers</span></span>(<span>text: str) ‑> list[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Scrape for u.s. phone numbers.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scrapePhoneNumbers(text: str) -&gt; list[str]:
    &#34;&#34;&#34;Scrape for u.s. phone numbers.&#34;&#34;&#34;
    numbers = []
    text = text.replace(&#34;+1&#34;, &#34;&#34;)
    for separator in &#34;-.&#34;:
        numbers.extend(findBySeparator(text, separator))
    numbers.extend(findByHref(text))
    numbers = [
        number
        for number in numbers
        if phonenumbers.is_valid_number(phonenumbers.parse(&#34;+1&#34; + number))
    ]
    numbers = sorted(list(set(numbers)))
    return numbers</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="scrapeTools.LinkScraper"><code class="flex name class">
<span>class <span class="ident">LinkScraper</span></span>
<span>(</span><span>htmlSrc: str, pageUrl: str)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class LinkScraper:
    def __init__(self, htmlSrc: str, pageUrl: str):
        self.soup = BeautifulSoup(htmlSrc, features=&#34;html.parser&#34;)
        self.parsedUrl = urlparse(pageUrl)
        self.pageLinks = []
        self.imgLinks = []
        self.scriptLinks = []

    def formatRelativeLinks(self, links: list[str]) -&gt; list[str]:
        &#34;&#34;&#34;Parses list of links and constructs a full url
        according to self.parsedUrl for the ones that don&#39;t have a
        &#39;netloc&#39; property returned by urlparse.

        Full urls are returned unedited other than stripping any
        leading or trailing forward slashes.&#34;&#34;&#34;
        formattedLinks = []
        for link in links:
            link = (
                link.strip(&#34; \n\t\r&#34;)
                .replace(&#39;&#34;&#39;, &#34;&#34;)
                .replace(&#34;\\&#34;, &#34;&#34;)
                .replace(&#34;&#39;&#34;, &#34;&#34;)
            )
            parsedUrl = urlparse(link)
            if all(ch not in link for ch in &#34;@ &#34;):
                parsedUrl = list(parsedUrl)
                if parsedUrl[0] == &#34;&#34;:
                    parsedUrl[0] = self.parsedUrl.scheme
                if parsedUrl[1] == &#34;&#34;:
                    parsedUrl[1] = self.parsedUrl.netloc
                formattedLinks.append(urlunparse(parsedUrl).strip(&#34;/&#34;))
        return formattedLinks

    def removeDuplicates(self, obj: list) -&gt; list:
        &#34;&#34;&#34;Removes duplicate members.&#34;&#34;&#34;
        return list(set(obj))

    def processLinks(self, links: list[str]) -&gt; list[str]:
        &#34;&#34;&#34;Formats relative links, removes duplicates, and sorts in alphabetical order.&#34;&#34;&#34;
        return sorted(self.removeDuplicates(self.formatRelativeLinks(links)))

    def findAll(self, tagName: str, attributeName: str) -&gt; list[str]:
        &#34;&#34;&#34;Finds all results according to tagName and attributeName.\n
        Filters out fragments.&#34;&#34;&#34;
        return [
            tag.get(attributeName)
            for tag in self.soup(tagName, recursive=True)
            if tag.get(attributeName) is not None and &#34;#&#34; not in tag.get(attributeName)
        ]

    def filterSameSite(self, links: list[str]) -&gt; list[str]:
        &#34;&#34;&#34;Filters out links that don&#39;t match self.parsedUrl.netloc&#34;&#34;&#34;
        return [
            link
            for link in links
            if urlparse(link).netloc.strip(&#34;www.&#34;)
            == self.parsedUrl.netloc.strip(&#34;www.&#34;)
        ]

    def scrapePageLinks(self):
        &#34;&#34;&#34;Scrape links from href attribute of &lt;a&gt; and &lt;link&gt; tags.&#34;&#34;&#34;
        links = self.findAll(&#34;a&#34;, &#34;href&#34;)
        links.extend(self.findAll(&#34;link&#34;, &#34;href&#34;))
        self.pageLinks = self.processLinks(links)

    def scrapeImgLinks(self):
        &#34;&#34;&#34;Scrape links from src attribute of &lt;img&gt; tags.&#34;&#34;&#34;
        self.imgLinks = self.processLinks(
            self.findAll(&#34;img&#34;, &#34;src&#34;) + self.findAll(&#34;img&#34;, &#34;data-src&#34;)
        )

    def scrapeScriptLinks(self):
        &#34;&#34;&#34;Scrape script links from src attribute of &lt;script&gt; tags.&#34;&#34;&#34;
        self.scriptLinks = self.processLinks(self.findAll(&#34;script&#34;, &#34;src&#34;))

    def scrapePage(self):
        &#34;&#34;&#34;Scrape all link types.&#34;&#34;&#34;
        for scrape in [
            self.scrapePageLinks,
            self.scrapeImgLinks,
            self.scrapeScriptLinks,
        ]:
            scrape()
        self.mergeImageLinksFromNonImgTags()

    def mergeImageLinksFromNonImgTags(self):
        &#34;&#34;&#34;Finds links in self.scriptLinks and self.pageLinks
        that have one of these image file extensions and adds them
        to self.imgLinks&#34;&#34;&#34;
        formats = [
            &#34;.jpg&#34;,
            &#34;.jpeg&#34;,
            &#34;.png&#34;,
            &#34;.svg&#34;,
            &#34;.bmp&#34;,
            &#34;.tiff&#34;,
            &#34;.pdf&#34;,
            &#34;.eps&#34;,
            &#34;.gif&#34;,
            &#34;.jfif&#34;,
            &#34;.webp&#34;,
            &#34;.heif&#34;,
            &#34;.avif&#34;,
            &#34;.bat&#34;,
            &#34;.bpg&#34;,
        ]
        for link in self.scriptLinks + self.pageLinks:
            if any(ext in link for ext in formats):
                self.imgLinks.append(link)
        self.imgLinks = sorted(self.removeDuplicates(self.imgLinks))

    def getLinks(
        self,
        linkType: str = &#34;all&#34;,
        sameSiteOnly: bool = False,
        excludedLinks: list[str] = None,
    ) -&gt; list[str]:
        &#34;&#34;&#34;Returns a list of urls found on the page.

        :param linkType: Can be &#39;all&#39;, &#39;page&#39;, &#39;img&#39;, or &#39;script&#39;.

        :param sameSiteOnly: Excludes external urls if True.

        :param excludedLinks: A list of urls to filter out of the results.
        Useful for excluding duplicates when recursively scraping a website.
        Can also be used with linkType=&#39;all&#39; to get two link types in one call:

        e.g. links = linkScraper.getLinks(linkType = &#39;all&#39;, excludedLinks = linkScraper.scriptLinks)
        will return page links and img links.&#34;&#34;&#34;
        match linkType:
            case &#34;all&#34;:
                links = self.removeDuplicates(
                    self.pageLinks + self.imgLinks + self.scriptLinks
                )
            case &#34;page&#34;:
                links = self.pageLinks
            case &#34;img&#34;:
                links = self.imgLinks
            case &#34;script&#34;:
                links = self.scriptLinks
        if sameSiteOnly:
            links = self.filterSameSite(links)
        if excludedLinks:
            links = [link for link in links if link not in excludedLinks]
        return sorted(links)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="scrapeTools.LinkScraper.filterSameSite"><code class="name flex">
<span>def <span class="ident">filterSameSite</span></span>(<span>self, links: list[str]) ‑> list[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Filters out links that don't match self.parsedUrl.netloc</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def filterSameSite(self, links: list[str]) -&gt; list[str]:
    &#34;&#34;&#34;Filters out links that don&#39;t match self.parsedUrl.netloc&#34;&#34;&#34;
    return [
        link
        for link in links
        if urlparse(link).netloc.strip(&#34;www.&#34;)
        == self.parsedUrl.netloc.strip(&#34;www.&#34;)
    ]</code></pre>
</details>
</dd>
<dt id="scrapeTools.LinkScraper.findAll"><code class="name flex">
<span>def <span class="ident">findAll</span></span>(<span>self, tagName: str, attributeName: str) ‑> list[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Finds all results according to tagName and attributeName.</p>
<p>Filters out fragments.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def findAll(self, tagName: str, attributeName: str) -&gt; list[str]:
    &#34;&#34;&#34;Finds all results according to tagName and attributeName.\n
    Filters out fragments.&#34;&#34;&#34;
    return [
        tag.get(attributeName)
        for tag in self.soup(tagName, recursive=True)
        if tag.get(attributeName) is not None and &#34;#&#34; not in tag.get(attributeName)
    ]</code></pre>
</details>
</dd>
<dt id="scrapeTools.LinkScraper.formatRelativeLinks"><code class="name flex">
<span>def <span class="ident">formatRelativeLinks</span></span>(<span>self, links: list[str]) ‑> list[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Parses list of links and constructs a full url
according to self.parsedUrl for the ones that don't have a
'netloc' property returned by urlparse.</p>
<p>Full urls are returned unedited other than stripping any
leading or trailing forward slashes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def formatRelativeLinks(self, links: list[str]) -&gt; list[str]:
    &#34;&#34;&#34;Parses list of links and constructs a full url
    according to self.parsedUrl for the ones that don&#39;t have a
    &#39;netloc&#39; property returned by urlparse.

    Full urls are returned unedited other than stripping any
    leading or trailing forward slashes.&#34;&#34;&#34;
    formattedLinks = []
    for link in links:
        link = (
            link.strip(&#34; \n\t\r&#34;)
            .replace(&#39;&#34;&#39;, &#34;&#34;)
            .replace(&#34;\\&#34;, &#34;&#34;)
            .replace(&#34;&#39;&#34;, &#34;&#34;)
        )
        parsedUrl = urlparse(link)
        if all(ch not in link for ch in &#34;@ &#34;):
            parsedUrl = list(parsedUrl)
            if parsedUrl[0] == &#34;&#34;:
                parsedUrl[0] = self.parsedUrl.scheme
            if parsedUrl[1] == &#34;&#34;:
                parsedUrl[1] = self.parsedUrl.netloc
            formattedLinks.append(urlunparse(parsedUrl).strip(&#34;/&#34;))
    return formattedLinks</code></pre>
</details>
</dd>
<dt id="scrapeTools.LinkScraper.getLinks"><code class="name flex">
<span>def <span class="ident">getLinks</span></span>(<span>self, linkType: str = 'all', sameSiteOnly: bool = False, excludedLinks: list[str] = None) ‑> list[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a list of urls found on the page.</p>
<p>:param linkType: Can be 'all', 'page', 'img', or 'script'.</p>
<p>:param sameSiteOnly: Excludes external urls if True.</p>
<p>:param excludedLinks: A list of urls to filter out of the results.
Useful for excluding duplicates when recursively scraping a website.
Can also be used with linkType='all' to get two link types in one call:</p>
<p>e.g. links = linkScraper.getLinks(linkType = 'all', excludedLinks = linkScraper.scriptLinks)
will return page links and img links.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getLinks(
    self,
    linkType: str = &#34;all&#34;,
    sameSiteOnly: bool = False,
    excludedLinks: list[str] = None,
) -&gt; list[str]:
    &#34;&#34;&#34;Returns a list of urls found on the page.

    :param linkType: Can be &#39;all&#39;, &#39;page&#39;, &#39;img&#39;, or &#39;script&#39;.

    :param sameSiteOnly: Excludes external urls if True.

    :param excludedLinks: A list of urls to filter out of the results.
    Useful for excluding duplicates when recursively scraping a website.
    Can also be used with linkType=&#39;all&#39; to get two link types in one call:

    e.g. links = linkScraper.getLinks(linkType = &#39;all&#39;, excludedLinks = linkScraper.scriptLinks)
    will return page links and img links.&#34;&#34;&#34;
    match linkType:
        case &#34;all&#34;:
            links = self.removeDuplicates(
                self.pageLinks + self.imgLinks + self.scriptLinks
            )
        case &#34;page&#34;:
            links = self.pageLinks
        case &#34;img&#34;:
            links = self.imgLinks
        case &#34;script&#34;:
            links = self.scriptLinks
    if sameSiteOnly:
        links = self.filterSameSite(links)
    if excludedLinks:
        links = [link for link in links if link not in excludedLinks]
    return sorted(links)</code></pre>
</details>
</dd>
<dt id="scrapeTools.LinkScraper.mergeImageLinksFromNonImgTags"><code class="name flex">
<span>def <span class="ident">mergeImageLinksFromNonImgTags</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Finds links in self.scriptLinks and self.pageLinks
that have one of these image file extensions and adds them
to self.imgLinks</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def mergeImageLinksFromNonImgTags(self):
    &#34;&#34;&#34;Finds links in self.scriptLinks and self.pageLinks
    that have one of these image file extensions and adds them
    to self.imgLinks&#34;&#34;&#34;
    formats = [
        &#34;.jpg&#34;,
        &#34;.jpeg&#34;,
        &#34;.png&#34;,
        &#34;.svg&#34;,
        &#34;.bmp&#34;,
        &#34;.tiff&#34;,
        &#34;.pdf&#34;,
        &#34;.eps&#34;,
        &#34;.gif&#34;,
        &#34;.jfif&#34;,
        &#34;.webp&#34;,
        &#34;.heif&#34;,
        &#34;.avif&#34;,
        &#34;.bat&#34;,
        &#34;.bpg&#34;,
    ]
    for link in self.scriptLinks + self.pageLinks:
        if any(ext in link for ext in formats):
            self.imgLinks.append(link)
    self.imgLinks = sorted(self.removeDuplicates(self.imgLinks))</code></pre>
</details>
</dd>
<dt id="scrapeTools.LinkScraper.processLinks"><code class="name flex">
<span>def <span class="ident">processLinks</span></span>(<span>self, links: list[str]) ‑> list[str]</span>
</code></dt>
<dd>
<div class="desc"><p>Formats relative links, removes duplicates, and sorts in alphabetical order.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def processLinks(self, links: list[str]) -&gt; list[str]:
    &#34;&#34;&#34;Formats relative links, removes duplicates, and sorts in alphabetical order.&#34;&#34;&#34;
    return sorted(self.removeDuplicates(self.formatRelativeLinks(links)))</code></pre>
</details>
</dd>
<dt id="scrapeTools.LinkScraper.removeDuplicates"><code class="name flex">
<span>def <span class="ident">removeDuplicates</span></span>(<span>self, obj: list) ‑> list</span>
</code></dt>
<dd>
<div class="desc"><p>Removes duplicate members.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def removeDuplicates(self, obj: list) -&gt; list:
    &#34;&#34;&#34;Removes duplicate members.&#34;&#34;&#34;
    return list(set(obj))</code></pre>
</details>
</dd>
<dt id="scrapeTools.LinkScraper.scrapeImgLinks"><code class="name flex">
<span>def <span class="ident">scrapeImgLinks</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Scrape links from src attribute of <img> tags.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scrapeImgLinks(self):
    &#34;&#34;&#34;Scrape links from src attribute of &lt;img&gt; tags.&#34;&#34;&#34;
    self.imgLinks = self.processLinks(
        self.findAll(&#34;img&#34;, &#34;src&#34;) + self.findAll(&#34;img&#34;, &#34;data-src&#34;)
    )</code></pre>
</details>
</dd>
<dt id="scrapeTools.LinkScraper.scrapePage"><code class="name flex">
<span>def <span class="ident">scrapePage</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Scrape all link types.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scrapePage(self):
    &#34;&#34;&#34;Scrape all link types.&#34;&#34;&#34;
    for scrape in [
        self.scrapePageLinks,
        self.scrapeImgLinks,
        self.scrapeScriptLinks,
    ]:
        scrape()
    self.mergeImageLinksFromNonImgTags()</code></pre>
</details>
</dd>
<dt id="scrapeTools.LinkScraper.scrapePageLinks"><code class="name flex">
<span>def <span class="ident">scrapePageLinks</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Scrape links from href attribute of <a> and <link> tags.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scrapePageLinks(self):
    &#34;&#34;&#34;Scrape links from href attribute of &lt;a&gt; and &lt;link&gt; tags.&#34;&#34;&#34;
    links = self.findAll(&#34;a&#34;, &#34;href&#34;)
    links.extend(self.findAll(&#34;link&#34;, &#34;href&#34;))
    self.pageLinks = self.processLinks(links)</code></pre>
</details>
</dd>
<dt id="scrapeTools.LinkScraper.scrapeScriptLinks"><code class="name flex">
<span>def <span class="ident">scrapeScriptLinks</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Scrape script links from src attribute of <script> tags.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def scrapeScriptLinks(self):
    &#34;&#34;&#34;Scrape script links from src attribute of &lt;script&gt; tags.&#34;&#34;&#34;
    self.scriptLinks = self.processLinks(self.findAll(&#34;script&#34;, &#34;src&#34;))</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3><a href="#header-submodules">Sub-modules</a></h3>
<ul>
<li><code><a title="scrapeTools.emailScraper" href="emailScraper.html">scrapeTools.emailScraper</a></code></li>
<li><code><a title="scrapeTools.inputScraper" href="inputScraper.html">scrapeTools.inputScraper</a></code></li>
<li><code><a title="scrapeTools.linkScraper" href="linkScraper.html">scrapeTools.linkScraper</a></code></li>
<li><code><a title="scrapeTools.phoneScraper" href="phoneScraper.html">scrapeTools.phoneScraper</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="scrapeTools.scrapeEmails" href="#scrapeTools.scrapeEmails">scrapeEmails</a></code></li>
<li><code><a title="scrapeTools.scrapeInputs" href="#scrapeTools.scrapeInputs">scrapeInputs</a></code></li>
<li><code><a title="scrapeTools.scrapePhoneNumbers" href="#scrapeTools.scrapePhoneNumbers">scrapePhoneNumbers</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="scrapeTools.LinkScraper" href="#scrapeTools.LinkScraper">LinkScraper</a></code></h4>
<ul class="">
<li><code><a title="scrapeTools.LinkScraper.filterSameSite" href="#scrapeTools.LinkScraper.filterSameSite">filterSameSite</a></code></li>
<li><code><a title="scrapeTools.LinkScraper.findAll" href="#scrapeTools.LinkScraper.findAll">findAll</a></code></li>
<li><code><a title="scrapeTools.LinkScraper.formatRelativeLinks" href="#scrapeTools.LinkScraper.formatRelativeLinks">formatRelativeLinks</a></code></li>
<li><code><a title="scrapeTools.LinkScraper.getLinks" href="#scrapeTools.LinkScraper.getLinks">getLinks</a></code></li>
<li><code><a title="scrapeTools.LinkScraper.mergeImageLinksFromNonImgTags" href="#scrapeTools.LinkScraper.mergeImageLinksFromNonImgTags">mergeImageLinksFromNonImgTags</a></code></li>
<li><code><a title="scrapeTools.LinkScraper.processLinks" href="#scrapeTools.LinkScraper.processLinks">processLinks</a></code></li>
<li><code><a title="scrapeTools.LinkScraper.removeDuplicates" href="#scrapeTools.LinkScraper.removeDuplicates">removeDuplicates</a></code></li>
<li><code><a title="scrapeTools.LinkScraper.scrapeImgLinks" href="#scrapeTools.LinkScraper.scrapeImgLinks">scrapeImgLinks</a></code></li>
<li><code><a title="scrapeTools.LinkScraper.scrapePage" href="#scrapeTools.LinkScraper.scrapePage">scrapePage</a></code></li>
<li><code><a title="scrapeTools.LinkScraper.scrapePageLinks" href="#scrapeTools.LinkScraper.scrapePageLinks">scrapePageLinks</a></code></li>
<li><code><a title="scrapeTools.LinkScraper.scrapeScriptLinks" href="#scrapeTools.LinkScraper.scrapeScriptLinks">scrapeScriptLinks</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>