Metadata-Version: 2.1
Name: serotiny
Version: 0.0.9.dev202301192335
Summary: A framework of tools to structure, configure and drive deep learning projects
Home-page: https://allencell.github.io/serotiny
License: BSD-3
Author: Guilherme Pires
Author-email: guilherme.pires@alleninstitute.org
Requires-Python: >=3.8,<4.0
Classifier: License :: Other/Proprietary License
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Provides-Extra: dev
Provides-Extra: docs
Provides-Extra: test
Requires-Dist: PyYAML (>=6.0,<7.0)
Requires-Dist: aicsimageio (>=4.6.4,<5.0.0)
Requires-Dist: fire (>=0.4.0,<0.5.0)
Requires-Dist: frozendict (>=2.3.2,<3.0.0)
Requires-Dist: fsspec (>=2022.3.0,<2023.0.0)
Requires-Dist: furo (>=2022.9.29,<2023.0.0) ; extra == "docs"
Requires-Dist: grpcio (>=1.46.0,<2.0.0)
Requires-Dist: hydra-core (>=1.2.0,<2.0.0)
Requires-Dist: joblib (>=1.2.0,<2.0.0)
Requires-Dist: jupyter-core (>=4.11.2,<5.0.0)
Requires-Dist: lightning-bolts (>=0.6.0.post1,<0.7.0) ; extra == "test"
Requires-Dist: m2r2 (>=0.3.3,<0.4.0) ; extra == "docs"
Requires-Dist: makefun (>=1.13.1,<2.0.0)
Requires-Dist: mlflow (>=1.30.0,<2.0.0)
Requires-Dist: modin (>=0.16.2,<0.17.0)
Requires-Dist: nbformat (>=5.2.0,<6.0.0)
Requires-Dist: numpy (>=1.22,<2.0)
Requires-Dist: ome-zarr (>=0.6.1,<0.7.0)
Requires-Dist: omegaconf (>=2.2.2,<3.0.0)
Requires-Dist: packaging (>=21.3,<22.0)
Requires-Dist: pandas (>=1.1,<2.0)
Requires-Dist: pip (>=22.1.2,<23.0.0)
Requires-Dist: pre-commit (>=2.20.0,<3.0.0) ; extra == "test" or extra == "dev"
Requires-Dist: protobuf (<4.0.0)
Requires-Dist: pyarrow (>=7.0.0,<8.0.0)
Requires-Dist: pycryptodome (>=3.14.1,<4.0.0)
Requires-Dist: pytest (>=7.2.0,<8.0.0) ; extra == "test"
Requires-Dist: pytest-cov (>=4.0.0,<5.0.0) ; extra == "test"
Requires-Dist: pytorch-lightning (>=1.6.0,<2.0.0)
Requires-Dist: s3fs (>=2022.3.0,<2023.0.0)
Requires-Dist: scanpy (>=1.9.1,<2.0.0)
Requires-Dist: scikit-learn (>=1.0.2,<2.0.0)
Requires-Dist: sphinx (>=5.3.0,<6.0.0) ; extra == "docs"
Requires-Dist: torch (>=1.11.0,<2.0.0)
Requires-Dist: torchvision (>=0.14.0,<0.15.0) ; extra == "test"
Requires-Dist: tox (>=3.27.0,<4.0.0) ; extra == "test"
Requires-Dist: universal-pathlib (>=0.0.20,<0.0.21)
Project-URL: Documentation, https://allencell.github.io/serotiny
Project-URL: Repository, https://github.com/AllenCell/serotiny
Description-Content-Type: text/markdown

# serotiny

While going about the work of building deep learning projects, several simultaneous problems seemed to emerge:

* How do we reuse as much work from previous projects as possible, and focus on building the part of the project that makes it distinct?
* How can we automate the generation of new models that are based on existing models, but vary in a crucial yet non-trivial way?
* When generating a multiplicity of related models, how can we keep all of the results, predictions, and analyses straight?
* How can the results from any number of trainings and predictions be compared and integrated in an insightful yet generally applicable way?

Serotiny arose from the need to address these issues and convert the complexity of deep learning projects into something simple, reproducible, configurable, and automatable at scale.

Serotiny is still a work-in-progress, but as we go along the solutions to these problems become more clear. Maybe you've run into similar situations? We'd love to hear from you.

## Overview

`serotiny` is a framework and set of tools to structure, configure and drive deep
learning projects, developed with the intention of streamlining the lifecycle of
deep learning projects at [Allen Institute for Cell Science](https://www.allencell.org/).

It achieves this goal by:

- Standardizing the structure of DL projects
- Relying on the modularity afforded by this standard structure to make DL projects highly
  configurable, using [hydra](https://hydra.cc) as the framework for configuration
- Making it easy to adopt best-practices and latest-developments in DL infrastructure
  by tightly integrating with
    - [Pytorch Lightning](https://pytorchlightning.ai) for neural net training/testing/prediction
    - [MLFlow](https://mlflow.org) for experiment tracking and artifact management

In doing so, DL projects become reproducible, easy to collaborate on and can
benefit from general and powerful tooling.

## Getting started

For more information, check our [documentation](https://allencell.github.io/serotiny),
or jump straight into our [getting started](https://allencell.github.io/serotiny/getting_started.html)
page, and learn how training a DL model can be as simple as:

``` sh

$ serotiny train data=my_dataset model=my_model

```

## Authors

- Guilherme Pires @colobas
- Ryan Spangler @prismofeverything
- Ritvik Vasan @ritvikvasan
- Caleb Chan @calebium
- Theo Knijnenburg @tknijnen
- Nick Gomez @gomeznick86

## Citing

If you find serotiny useful, please cite this repository as:

```
Serotiny Authors (2022). Serotiny: a framework of tools to structure, configure and drive deep learning projects [Computer software]. GitHub. https://github.com/AllenCellModeling/serotiny
Free software: BSD-3-Clause
```

