def info():
    print('task1(), task2(),task3(), equation-дается уравнение, ошибки и корр, mean_app- аппроксимация, mgk - метод глав компонет')


def task1():
    print('Нелинейно non_linear1()')
    print('Значимость регрессии в целом reg_signf1)()')
    print('Значимость параметров par_signf1()')
    print('Интервальные оценки параметров int_par1()')
    print('Смысли коэф детерминации point_det1()')
    print('Дельта коэффициенты delta1()')
    print('Скорр коэф детерминации adj_det1()')
    print('Эластичность elasticity1()')
    print('Корреляция corr_signf1()')


def task1():
    print('Нелинейно non_linear1()')
    print('Значимость регрессии в целом reg_signf1)()')
    print('Значимость параметров par_signf1()')
    print('Интервальные оценки параметров int_par1()')
    print('Смысли коэф детерминации point_det1()')
    print('Дельта коэффициенты delta1()')
    print('Скорр коэф детерминации adj_det1()')
    print('Эластичность elasticity1()')
    print('Корреляция corr_signf1()')
 

def non_linear1():
    print('''
    Нелинейно:
1) Линеаризуем:
кобба-дугласа, x^b, b^x– логарифмируем
логарифмическая – потенцируем (возводим в е)
Гиперболическая b/x -> x = lnx
''')
 

def reg_signf1():
    print('''
    Проверьте статистическую значимость регрессии в целом.
1) F расч дано в регрессионной таблице
2) F таб = F.ОБР.ПХ(0,05;Количество переменных-1;Наблюдения-2)
3) Если F расч > F таб => уравнение значимо
''')


def par_signf1():
    print('''
    Проверьте статистическую значимость оценок параметров модели
1) t расч дано в регрессионной таблице
2) t таб = СТЬЮДЕНТ.ОБР.2Х(0,05;Наблюдения-2)
3) Если t расч > t таб => Параметры значимы
''')


def corr_signf1():
    print('''Корреляция:
1) Tтаб Стьюдент.обр.2х(0,05;наблюдения-2)
2) Корреляция =р
3) Ткрит = р*КОРЕНЬ(наблюдения-2)/КОРЕНЬ(1-р^2)
4) t расч   >   t таб корреляция значима
''')


def int_par1():
    print('''
    Рассчитайте интервальные оценки для параметров модели
 Расчитать t таб= СТЬЮДЕНТ.ОБР.2Х(0,05;Наблюдения-2)
 P верх = коэффициент + t таб * 1-коэф^2/(наблюдения-2)
 P ниж = коэффициент - t таб * 1-коэф^2/(наблюдения-2)
''')


def point_det1():
    print('''
    Запишите смысл полученного коэффициента детерминации
    Показывает какая доля дисперсии результативного признака объясняется влиянием независимых переменных
''')


def delta1():
    print('''Дельта коэффициенты модели показывает долю влияния фактора в суммарном влиянии всех факторов.
\Delta_j=r_{yx} {beta_j}/{R^2} . Тут beta_j =a_j {sigma_{xj}}/{sigma_y}
''')
 

def adj_det1():
    print('''
    1) R^2_скорр = 1- (1-R^2) * (n-1)/(n-m)  m = k+1
Скорректированный коэффициент детерминации (R2adj) - коэффициент детерминации, скорректированный на число факторов, и не чувствительный к числу регрессоров. 
''')
 

def elasticity1():
    print('''
    1)  (delta q / delta p) = коэф при параметре. = q’
2) q’*(p0/q0). Например, среднее
3) Коэффициент эластичности показывает, насколько во среднем изменится Y при изменении X на 1%.
''')


def task2():
    print('Гетероскедастичность - spearman2()')
    print('Гетероскедастичность - golf_quandt2()')
    print('Автокорреляция dw2()')
    print('Нормальность scipy.stats.shapiro()')
    print('Нормальность scipy.stats.anderson(, dist="norm")')
    print('VIF vif2()')
    print('gauss_markov()')


def spearman2():
    print('''
Гомоскедастичность (тест Спирмена)
1) Построить регрессию 
2) Проранжировать ошибки и x = РАНГ(элемент; столбец;1)
3) Рассчитать корреляцию двух столбцов рангов = р
4) Расчетное t – статистика t_p = (р^2) * sqrt(наблюдение-2) /(sqrt(1-p^2))
5) T табл =СТЬЮДЕНТ.ОБР.2Х(0,05;наблюдение-2)
6) Если tр >tкр, то гипотеза H0 отвергается, коэффициент Спирмена статистически значим, гетероскедастичность есть (дисперсии не равны, плохо).
''')


def golf_quandt2():
    print('''
Гомоскедастичность (тест Голфелда-Куандта)
1) Все наблюдения n упорядочиваются по величине x.
2) Вся упорядоченная выборка разбивается на 3 части: k, (n-k), k. N=20, k=8
3) Строим регрессию для первых k наблюдений и для третьих k наблюдений. 
4) По каждой подвыборке рассчитывается сумма квадратов отклонений:
S_1 = sum(e^2)          S_3 = sum(e^2)
5) Рассчитываем F статистику = S3/S1 
6) Fкр(α,υ1= υ2=k-m-1). = F.ОБР.ПХ
7) Сравнение Fрасч > Fкр(α, υ1= υ2=k-m-1), гетероскедастичность.
''')
 

def dw2():
    print('''
Дарбин-Уотсон
1) Строим регрессию
2) Составить столбец ошибок и еще один смещенный вниз (на 1) столбец ошибок
3) DW = (sum_{t-2} ^ n ((e_t- e_{t-1})^2) ) / sum_{t=1}^n (e_t^2)          # (et – e(t-1) )^2/ et^2 
4) По Таблице, зная количество наблюдений (n) и количество объясняющих переменных (k), выбирают значения величин dL и dU.
5) Строится интервальная и проверяется, в какой из пяти интервалов попадает рассчитанное значение статистики DW, и на этом основании делается вывод
(0, dL) -> >0, 
(dL, dU,) -> ?, 
(dU, 4- dU) -> =0, 
(4- dU, 4- dL) -> ?, 
(4-dL, 4) -> <0 
6) Если вычисленное значение статистики попадает в интервалы:  0< DW< dL и 4-dL<DW<4 ,автокорреляция присутствует, и необходимо выполнить корректировку модели.
''')
 

def vif2():
    print('''
Мультиколлинеарность VIF
1) Построить регрессию
2) Строим новые регрессии для каждого отдельного параметра, где одна независимая переменная является переменной отклика, а остальные (без учета y)  - независимые 
3) VIF рассчитывается как 1/(1 – R Square) # R square для регрессии, где один параметр стал y, а остальные – независимые
Значение VIF начинается с 1 и не имеет верхнего предела. Общее эмпирическое правило для интерпретации VIF выглядит следующим образом:
Значение 1 указывает на отсутствие корреляции между данной независимой переменной и любыми другими независимыми переменными в модели.
Значение от 1 до 5 указывает на умеренную корреляцию между данной объясняющей переменной и другими независимыми переменными в модели, но часто она недостаточно серьезна, чтобы требовать внимания.
Значение больше 5 указывает на потенциально сильную корреляцию между данной независимой переменной и другими независимыми переменными в модели. В этом случае оценки коэффициентов и p-значения в выходных данных регрессии, вероятно, ненадежны.   
''')


def gauss_markov():
    print('''мат ожидание остатков = 0
    гомоскедастичность - постояноство дисперсий отклонений
    случ отклонения независимы (автокорреляция -)
    случ отклонения не зависят от переменной х (сигма остатков и х = 0)
    модель линейна
    отствует мультиколлинеарность
    остатки нормально распределены''')
 
def task3():
    print('''
Вопрос 3
1) Осуществить прогноз Y при значении фактора X равного {выражение}
Чтобы там дальше не было подставляем в уравнение вместо X {выражение}
2) Для интервала int_par1
''')
 

def equation():
    print('''
Дается уравнение регрессии, ст ошибки и множ коэф корреляции
1) Оценить значимость параметров
H0 коэф=0
Var = sigma^2 , E = коэф. 
t ~ (0- коэф) / sigma
СТЬЮДЕНТ.ОБР.2Х
2) H0 R^2 =0 (тут уже можно окончить, но если хочется подушнить)
R^2 = r^2
F = (R^2 / (1-R^2)) * (n-k)/(k-1)
F.ОБР.ПХ() k-1; n-k – количество всех переменных   
''')


def mean_app():
    print('''1) =1/наблюдения*сумма(е/у) *100''')


def mgk():
    print('''
from sklearn.preprocessing import StandardScaler
from numpy.linalg import eig
features = ['x1', 'x2', 'x3']
x = df [features].to_numpy()
x = StandardScaler().fit_transform(x)
a = pd.DataFrame(x).corr().to_numpy()
w, v = eig(a)
print("Собственные значения")
w
print("Доля объясненной дисперсии исходных переменных каждой компонентой")
w / k
''')
