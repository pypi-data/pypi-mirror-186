{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fol_embedding import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Environment()\n",
    "e.declare_function(\"f\", [\"A\"], \"A\")\n",
    "e.declare_function(\"c\", [], \"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(= (f c) c) => (= c c)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.declare_sequent(\"(f c) = (f x) => (f y) = c\")\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([(('c', []), ('c', []))], [(('c', []), ('c', []))]),\n",
       " ([(('f', [('c', [])]), ('c', []))], [(('c', []), ('c', []))])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.sequents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlusOneNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PlusOneNet, self).__init__()\n",
    "        self.linear0 = torch.nn.Linear(1, 2)\n",
    "        self.linear1 = torch.nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.linear0(x))\n",
    "        x = self.linear1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultNet, self).__init__()\n",
    "        self.linear0 = torch.nn.Linear(2, 3)\n",
    "        self.linear1 = torch.nn.Linear(3, 3)\n",
    "        self.linear2 = torch.nn.Linear(3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.relu(self.linear0(x))\n",
    "        x = torch.nn.functional.relu(self.linear1(x))\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        In the constructor we instantiate five parameters and assign them as members.\n",
    "        \"\"\"\n",
    "        super(DynamicNet, self).__init__()\n",
    "        self.plus1 = PlusOneNet()\n",
    "        self.mult = MultNet()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        For the forward pass of the model, we randomly choose either 4, 5\n",
    "        and reuse the e parameter to compute the contribution of these orders.\n",
    "\n",
    "        Since each forward pass builds a dynamic computation graph, we can use normal\n",
    "        Python control-flow operators like loops or conditional statements when\n",
    "        defining the forward pass of the model.\n",
    "\n",
    "        Here we also see that it is perfectly safe to reuse the same parameter many\n",
    "        times when defining a computational graph.\n",
    "        \"\"\"\n",
    "        x1 = self.plus1(x)\n",
    "        x2 = self.plus1(x1)\n",
    "        return self.mult(torch.cat([x1, x2], dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicNet(\n",
       "  (plus1): PlusOneNet(\n",
       "    (linear0): Linear(in_features=1, out_features=2, bias=True)\n",
       "    (linear1): Linear(in_features=2, out_features=1, bias=True)\n",
       "  )\n",
       "  (mult): MultNet(\n",
       "    (linear0): Linear(in_features=2, out_features=3, bias=True)\n",
       "    (linear1): Linear(in_features=3, out_features=3, bias=True)\n",
       "    (linear2): Linear(in_features=3, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Tensors to hold input and outputs.\n",
    "x = torch.linspace(-math.pi, math.pi, 10000).reshape(-1, 1).to('cuda')\n",
    "y = x**2 + 3*x + 2\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = DynamicNet().to('cuda')\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct our loss function and an Optimizer. Training this strange model with\n",
    "# vanilla stochastic gradient descent is tough, so we use momentum\n",
    "criterion = torch.nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999 476136.96875\n",
      "3999 340705.6875\n",
      "5999 26045.84375\n",
      "7999 6750.94140625\n",
      "9999 6576.740234375\n",
      "11999 6477.23486328125\n",
      "13999 6418.181640625\n",
      "15999 6372.67578125\n",
      "17999 6330.88623046875\n",
      "19999 6291.73046875\n",
      "21999 6254.96630859375\n",
      "23999 6220.30908203125\n",
      "25999 6187.57080078125\n",
      "27999 6156.5673828125\n",
      "29999 6127.06640625\n"
     ]
    }
   ],
   "source": [
    "for t in range(30000):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if t % 2000 == 1999:\n",
    "        print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynamicNet(\n",
       "  (plus1): PlusOneNet(\n",
       "    (linear0): Linear(in_features=1, out_features=2, bias=True)\n",
       "    (linear1): Linear(in_features=2, out_features=1, bias=True)\n",
       "  )\n",
       "  (mult): MultNet(\n",
       "    (linear0): Linear(in_features=2, out_features=3, bias=True)\n",
       "    (linear1): Linear(in_features=3, out_features=3, bias=True)\n",
       "    (linear2): Linear(in_features=3, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7695]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.tensor([[-8.0]]).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.3119], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_submodule('plus1')(torch.tensor([0.0]).to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed94561f0d1834aff598abea6bc6aa21e572fc4f9353acca6b52b076dc139250"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
