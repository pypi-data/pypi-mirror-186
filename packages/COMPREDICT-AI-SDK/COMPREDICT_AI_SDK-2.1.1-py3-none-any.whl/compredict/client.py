import os
from json import dumps as json_dump, dump
from os import remove
from os.path import exists
from tempfile import NamedTemporaryFile
from typing import Optional, Union, List, Type

from pandas import DataFrame
from pandas.io.common import get_handle

from compredict.connection import Connection
from compredict.exceptions import ClientError, Error
from compredict.resources import resources
from compredict.singleton import Singleton
from compredict.utils.authentications import generate_token, generate_token_from_refresh_token, verify_token


@Singleton
class api:

    def __init__(self,
                 username: Optional[str] = None,
                 password: Optional[str] = None,
                 token: Optional[str] = None,
                 token_refresh: Optional[str] = None,
                 callback_url: Optional[str] = None,
                 url: Optional[str] = None,
                 validate: Optional[bool] = False):
        """
        COMPREDICT's AI Core Client that will provide an interface for communication. This class is singleton.

        :param username: User's username in AI Core.
        :param password: User's password to AI Core.
        :param token: API Key used for authorization.
        :param token_refresh: Token used, when 'token' value is expired, to generate new token.
        :param callback_url: URL for sending the results of long processes.
        :param url: URL to desired version of AI Core used.
        :param validate: indicates, if token should be validated (defaults to False)
        """
        self.url = api.BASE_URL.format(api.API_VERSION) if url is None else url
        self.connection = Connection(url=self.url)
        self.refresh_token = token_refresh

        if token is not None and validate:
            self.verify_token(token)
            self.token = token
        elif token is not None and not validate:
            self.token = token
        elif token is None and (username is not None and password is not None):
            self.generate_token(username, password)
        else:
            raise ValueError("No token, or username and password, provided.")

        self.callback_url = callback_url
        self.connection.set_token(self.token)

    def fail_on_error(self, option: bool = True):
        """
        Ability to choose whether to raise exception on receiving error or return false.

        :param option: Boolean, True is to raise exception otherwise return false on error.
        :return: None
        """
        self.connection.fail_on_error = option

    def verify_peer(self, option: str):
        """
        Prompt SSL connection

        :param option: Boolean True/False
        :return:
        """
        self.connection.ssl = option

    @property
    def last_error(self) -> Error:
        return self.connection.last_error

    def generate_token(self, username: str, password: str):
        """
        Generate access token and refresh token from username and password.
        Refresh token can be used later to generate new access token.

        By calling this method, instance of the client is automatically updated with
        new access_token and token_refresh.

        :param username: user's username in AI Core
        :param password: user's password to AI Core
        """
        response = generate_token(self.url, username, password)
        token = self.connection.handle_response(response, True)
        self.token = token['access']
        self.refresh_token = token['refresh']

    def generate_token_from_refresh_token(self, refresh_token: str = None):
        """
        Takes a refresh type JSON web token and returns an access type JSON web token if the refresh token is valid.

        By calling this method, instance of the client is automatically updated with new access token.
        :param refresh_token: refresh token generated by user with username and password
        """
        if refresh_token is None and self.refresh_token is None:
            raise ClientError("Please provide refresh token.")
        token = refresh_token if refresh_token is not None else self.refresh_token
        response = generate_token_from_refresh_token(self.url, token)
        token = self.connection.handle_response(response, True)
        self.token = token['access']

    def verify_token(self, token: str = None) -> bool:
        """
        Check if token is valid.

        :param token: token which user would like to verify
        :return: bool indicating if token is valid
        """
        if token is None and self.token is None:
            raise ClientError("Please provide token to verify.")
        token_to_verify = token if token is not None else self.token
        response = verify_token(self.url, token_to_verify)
        self.connection.handle_response(response, True)
        return True

    def _set_callback_urls(self, callback_url: Union[List[str], str]) -> str:
        """
        Accept list of urls and format them into one string with dividing '|' in between.
        This is the format accepted by ai core.
        :param callback_url: list of callback urls
        :return: one callback_url string
        """
        if isinstance(callback_url, list):
            multiple_callback = "|".join(callback_url)
        else:
            multiple_callback = callback_url

        return multiple_callback

    @staticmethod
    def __map_resource(
            resource: str,
            a_object: Union[dict, bool]
    ) -> Union[Type[resources.BaseResource], bool]:
        """
        Map the result to the correct resource

        :param resource: String name to the resource
        :param a_object: The values returned from the request.
        :return: New class of the resources with the response values.
        """
        if a_object is False:
            return a_object
        try:
            model_class = getattr(resources, resource)
            instance = model_class(**a_object)
        except (AttributeError, ModuleNotFoundError):
            raise ImportError("Resource {} was not found".format(resource))
        return instance

    @staticmethod
    def __map_collection(
            resource: str,
            objects: Union[dict, bool]
    ) -> Union[List[Type[resources.BaseResource]], bool]:
        """
        Create a list of resources if the results returns a list

        :param resource: String name to the resource
        :param objects: The list of values returned from the request.
        :return: List of instances of the given resource
        """
        if objects is False:
            return objects

        try:
            instances = list()
            for obj in objects:
                model_class = getattr(resources, resource)
                instances.append(model_class(**obj))
        except (AttributeError, ModuleNotFoundError):
            raise ImportError("Resource {} was not found".format(resource))
        return instances

    def get_algorithms(self) -> Union[List[resources.Algorithm], bool]:
        """
        Returns the collection of algorithms

        :return: list of algorithms
        """
        response = self.connection.GET('/algorithms')
        return self.__map_collection('Algorithm', response)

    def get_algorithm(self, algorithm_id: str) -> Union[resources.Algorithm, bool]:
        """
        Get the information of the given algorithm id

        :param algorithm_id: String identifier of the algorithm
        :return: Algorithm resource
        """
        response = self.connection.GET('/algorithms/{}'.format(algorithm_id))
        return self.__map_resource('Algorithm', response)

    @staticmethod
    def __raise_error_if_file_type_incorrect(path_to_file: str, type_of_file: str):
        """
        Features file can be only provided as .parquet, whereas parameters file can be only provided as .json.
        This method will raise ValueError if features/parameter file specified, breaks this rule.
        """
        _, extension = os.path.splitext(path_to_file)
        if type_of_file == "features" and extension != ".parquet":
            raise ValueError(f"Features file format: {extension} is not accepted. Parquet file is required.")
        elif type_of_file == "parameters" and extension != ".json":
            raise ValueError(f"Parameters file format: {extension} is not accepted. Json file is required.")

    def __process_data(self, data, type_of_data, compression=None):
        """
        Process the given data and convert it to file.

        In case of data provided as path to file, make sure that file is of correct type.

        In case of parameters provided as dict: create json file from dict.
        In case of features provided as dict: create DataFrame from dict and then write
        DataFrame into parquet file.
        In case of features provided as DataFrame: write DataFrame into parquet file.

        :param data: The data to be sent for computation and prediction.
        :type data: dict | str | pandas
        :param type_of_data: Data can be of type: 'features' or of type: 'parameters'.
        Features will be always converted into parquet file, whereas parameters into json file.
        :return: opened file, bool indicating if file should be removed afterwards.
        File is signed to be removed if TemporaryFile was generated from provided data.
        """
        if isinstance(data, str):
            self.__raise_error_if_file_type_incorrect(data, type_of_data)
            return open(data, "rb+"), False

        file = NamedTemporaryFile('wb+', delete=False)
        if type_of_data == "parameters":
            self.__write_json_file(file, data, compression=compression)

        if isinstance(data, dict):
            if type_of_data == 'parameters':
                self.__write_json_file(file, data, compression=compression)
            else:
                data = DataFrame(data)

        if type_of_data == 'features':
            data.to_parquet(file.name, compression=compression)
        return file, True

    @staticmethod
    def __write_json_file(t_file, data, compression=None):
        """
        Function to write JSON into a file and point again to the top of the file for reading.

        :param t_file: temporary file to contain the data
        :type t_file: tempfile.NamedTemporaryFile
        :param data: The data to be stored.
        :type data: dict
        :param compression: JSON compression type, same compression methods as in `to_json` in pandas.
        :type compression: string.
        :return: saved file.
        """
        file_handle = get_handle(t_file.name, "w", compression=compression)
        file = file_handle[0] if isinstance(file_handle, tuple) else file_handle.handle

        with file as f:
            dump(data, f)
        t_file.seek(0)

    @staticmethod
    def __remove_file(file, is_to_remove):
        """
        Remove temporary created file.
        """
        if file is not None:
            file.close()
            if is_to_remove and exists(file.name):
                remove(file.name)

    def run_algorithm(self,
                      algorithm_id: str,
                      features: Union[str, DataFrame, dict],
                      version: Optional[str] = None,
                      evaluate: bool = True,
                      callback_url: Optional[Union[str, List[str]]] = None,
                      callback_param: Optional[Union[dict, List[dict]]] = None,
                      parameters: Optional[Union[str, dict]] = None,
                      compression: Optional[str] = None,
                      monitor: bool = True) -> Union[resources.Task, resources.Result, bool]:
        """
        Run the given algorithm id with the passed data. The user have the ability to toggle encryption and evaluation.

        :param algorithm_id: String identifier of the algorithm
        :param features: Features can be specified as path to features .parquet file, dictionary
        or pandas.Dataframe.
        :param version: Choose the version of the algorithm you would like to call. Defaults to latest version.
        :param evaluate: Boolean to whether evaluate the results of predictions or not.
        :param callback_param: The callback additional parameter to be sent with results.
                               If multiple callback_urls are specified, different parameters can be defined for each
                               url. In this case list of dictionaries is required (each callback dict for each
                               callback url). If single callback dictionary is passed with list of callback urls -
                               then the same parameters will be send to all provided callback urls.
        :param callback_url: Callback urls that result will be send, once computed. Can be single url or multiple
                             urls in a list.
        :param parameters: Parameters used for configuration of algorithm (specific for each algorithm).
        :param compression: The compressed type of the data, the compression supported is what pandas supports \
        for the file content type you will send. Based on data type:
            - if data is pandas or dict, then the compression is done by the function.
            - if string or path, then it describes the compression of the file sent.
        :param monitor: Boolean to monitor the output results of the model or not.
        :return: Prediction if results are returned instantly or Task otherwise.
        """

        features_file, is_features_file_to_remove = None, False
        parameters_file, is_parameters_file_to_remove = None, False
        try:
            features_file, is_features_file_to_remove = self.__process_data(features, "features",
                                                                            compression=compression)
            if parameters:
                parameters_file, is_parameters_file_to_remove = self.__process_data(parameters, "parameters",
                                                                                    compression=compression)

            callback_url = self._set_callback_urls(
                callback_url) if callback_url is not None else self.callback_url

            params = dict(evaluate=self.__process_evaluate(evaluate), monitor=monitor,
                          callback_url=callback_url, callback_param=json_dump(callback_param),
                          compression=compression, version=version)

            files = {"features": ("features.parquet", features_file, "application/parquet"),
                     "parameters": ("parameters.json", parameters_file, "application/json")}

            response = self.connection.POST(f'/algorithms/{algorithm_id}/predict',
                                            data=params, files=files)
            resource = 'Task' if response is not False and 'job_id' in response else 'Result'
        finally:
            self.__remove_file(features_file, is_features_file_to_remove)
            self.__remove_file(parameters_file, is_parameters_file_to_remove)
        return self.__map_resource(resource, response)

    def train_algorithm(self,
                        algorithm_id: str,
                        features: Union[str, DataFrame, dict],
                        version: Optional[str] = None,
                        export_new_version: Optional[bool] = None,
                        parameters: Optional[Union[str, dict]] = None,
                        compression: Optional[str] = None,
                        monitor: bool = True) -> Union[resources.Task, bool]:
        """
        Train fit algorithm with the passed data.

        :param algorithm_id: String identifier of the algorithm.
        :param features: Features can be specified as path to features .parquet file, dictionary
        or pandas.Dataframe.
        :param version: Choose the version of the algorithm you would like to call. Default is latest version.
        :param export_new_version: The trained model will be exported to a new version if True.
               Otherwise, the requested version will be updated. If None, then the model’s default behavior
               will be executed. Default behaviour is controlled by the algorithm’s author.
        :param parameters: Parameters used for configuration of algorithm (specific for each algorithm).
        :param compression: The compressed type of the data, the compression supported is what pandas supports
               for the file content type you will send. Based on data type:
               - if data is pandas or dict, then the compression is done by the function.
               - if string or path, then it describes the compression of the file sent.
        :param monitor: Boolean to monitor the output results of the model or not
        :return: Task (since all processing fit algorithms always end up in queue).
        """
        features_file, to_remove_features = None, False
        parameters_file, to_remove_parameters = None, False

        try:
            features_file, is_features_file_to_remove = self.__process_data(features, "features",
                                                                            compression=compression)
            if parameters is not None:
                parameters_file, is_parameters_file_to_remove = self.__process_data(parameters, "parameters",
                                                                                    compression=compression)

            files = {"features": ("features.parquet", features_file, "application/parquet"),
                     "parameters": ("parameters.json", parameters_file, "application/json")}

            params = dict(export_new_version=export_new_version, compression=compression, version=version,
                          monitor=monitor)

            response = self.connection.POST('/algorithms/{}/fit'.format(algorithm_id),
                                            data=params, files=files)
        finally:
            self.__remove_file(features_file, to_remove_features)
            self.__remove_file(parameters_file, to_remove_parameters)
        return self.__map_resource("Task", response)

    @staticmethod
    def __process_evaluate(evaluate):
        """
        Check the type of evaluate parameter and parse it accordingly.

        :param evaluate: evaluation of the algorithm
        :type evaluate: bool|dict|string
        :return: bool|string
        """
        if isinstance(evaluate, dict):
            return json_dump(evaluate)
        return evaluate

    def cancel_task(self, task_id: str) -> Union[resources.Task, bool]:
        """
        Cancel running Task.

        :param task_id: String identifier of the job.
        :return: Cancelled task instance.
        """
        response = self.connection.DELETE('/algorithms/tasks/{}'.format(task_id))
        return self.__map_resource('Task', response)

    def get_task_results(self, task_id: str) -> Union[resources.Task, bool]:
        """
        Check COMPREDICT'S AI Core for the results of the computation.

        :param task_id: String identifier of the job.
        :return: The new results of the Task
        """
        response = self.connection.GET('/algorithms/tasks/{}'.format(task_id))
        return self.__map_resource('Task', response)

    def get_algorithm_versions(self, algorithm_id: str) -> Union[List[resources.Version], bool]:
        """
        Get all versions of an algorithm.

        :param algorithm_id: The id of the main algorithm
        :return: List of versions
        """
        response = self.connection.GET('/algorithms/{}/versions'.format(algorithm_id))
        if isinstance(response, list):
            [response[i].update(dict(algorithm_id=algorithm_id)) for i in range(len(response))]
        return self.__map_collection('Version', response)

    def get_algorithm_version(self, algorithm_id: str, version: str) -> Union[resources.Version, bool]:
        """
        Get a specific version of an algorithm.

        :param algorithm_id: The id of the main algorithm
        :param version: Specify the version of the algorithm
        :return: Version
        """
        response = self.connection.GET('/algorithms/{}/versions/{}'.format(algorithm_id, version))
        if isinstance(response, dict):
            response.update(dict(algorithm_id=algorithm_id))
        return self.__map_resource('Version', response)

    def get_template(self, algorithm_id: str,
                     file_type: str = 'input',
                     version: Optional[str] = None) -> NamedTemporaryFile:
        """
        Return the template that explains the data to be sent for the algorithms. Bear in mind, to close the file once
        done to delete it.

        :param algorithm_id: String identifier of the Algorithm.
        :param file_type: (default `input`) indicates from which algorithms template data graph should be retrieved.
            Can be 'input', 'output' or 'parameters'.
        :param version: (default None) version of algorithm from which template should be retrieved.
            Defaults to latest version of algorithm.
        :return: NamedTemporaryFile of the results.
        """
        get_args = self.__build_get_args(type=file_type, version=version)
        response = self.connection.GET('/algorithms/{}/template{}'.format(algorithm_id, get_args))
        return response

    def get_graph(self, algorithm_id: str, file_type: str,
                  version: Optional[str] = None) -> NamedTemporaryFile:
        """
        Return the graph that explains the input data to be sent for the algorithms.

        :param algorithm_id: String identifier of the algorithm.
        :param file_type: (default `input`) indicates from which algorithms template data graph should be retrieved.
            Can be 'input', 'output' or 'parameters'.
        :param version: (default None) version of algorithm from which graph should be retrieved.
            Defaults to latest version of algorithm.
        :return: NamedTemporaryFile of the results.
        """
        get_args = self.__build_get_args(type=file_type, version=version)
        response = self.connection.GET('/algorithms/{}/graph{}'.format(algorithm_id, get_args))
        return response

    @staticmethod
    def __build_get_args(**kwargs):
        return "?" + "&".join(
            ["{}={}".format(key, value) for key, value in kwargs.items() if value is not None])

    @staticmethod
    def __is_binary(filepath: str):
        """
        Return true if the given filename appears to be binary.
        File is considered to be binary if it contains a NULL byte.
        FIXME: This approach incorrectly reports UTF-16 as binary.
        """
        with open(filepath, 'rb') as f:
            for block in f:
                if b'\0' in block:
                    return True
        return False
